---
layout: post
title: The advantages of Item Response Theory
---

Today at Metis I presented on Item Response Theory (IRT), or a better way to evaluate student aptitude. The presentation was based on a <a href="http://www.knewton.com/tech/blog/2012/06/understanding-student-performance-with-item-response-theory/" target="_blank">blog post</a> from Knewton, an adaptive learning company that uses IRT to evaluate performance on tests.

Knewton is interesting because they are able to grab all this data along the learning process to gauge how the student learns and optimize the material for her, in real time. Collecting traditionally uncollected data is always cool to me really.

This presentation was inspired by my frustration with traditional measurement methods in the classroom. After reading a report designed to optimize measures of effective teaching, I was struck by the report's explanation of the variability in the data. For example, some of the reasons for fluctuations in value-added measures (student test scores, essentially) were:

* "a few rowdy kids who disrupt learning for everyone"
* "less than perfect test reliability"

First of all, the rowdy kids are likely not in the optimal learning environment for their personal learning style. Secondly, if the test is not so reliable in and of itself, what are high scores on the tests really measuring?

### My presention:

<iframe id="iframe_container" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" width="550" height="400" src="https://prezi.com/embed/xwcjeidjombp/?bgcolor=ffffff&amp;lock_to_path=0&amp;autoplay=0&amp;autohide_ctrls=0&amp;landing_data=bHVZZmNaNDBIWmlSa1k1MmNRK3VoaXFhTktOYzU5Ynl1eWtiVVRLK2V4VTZLM0pGczZTVEpSWEg2WkwzcEtiWFdHdz0&amp;landing_sign=0sY2UQX72v1Kc2S8B-GeyhoRgAxzKmh1RiJUiL_kWTU#"></iframe>